{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68534e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wooldridge as woo\n",
    "import statsmodels.formula.api as smf \n",
    "import patsy as pt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.base.model as smclass\n",
    "import linearmodels.iv as iv\n",
    "import linearmodels as plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd2ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch16 q2\n",
    "# corn = price + income is the demand function because a country's income may affect\n",
    "# the amount of corn its able to purchase, similar to the way an individual's salary would \n",
    "# impact their weekly grocery budget. \n",
    "# corn = price + rainfall + rainfall^2 is the supply function because rainfall obviously \n",
    "# alters the amount of corn a country's crops will successfully produce. \n",
    "# the econometric identification of these two equations is sound because  both the order\n",
    "# and rank conditions are met given that income is present in demand but not supply while\n",
    "# rainfall is included with supply and not demand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40df68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                lincome   R-squared:                       0.165\n",
      "Model:                            OLS   Adj. R-squared:                  0.161\n",
      "Method:                 Least Squares   F-statistic:                     39.61\n",
      "Date:                Sat, 23 Apr 2022   Prob (F-statistic):           2.68e-30\n",
      "Time:                        18:13:13   Log-Likelihood:                -798.50\n",
      "No. Observations:                 807   AIC:                             1607.\n",
      "Df Residuals:                     802   BIC:                             1630.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.7954      0.170     45.741      0.000       7.461       8.130\n",
      "cigs           0.0017      0.002      1.010      0.313      -0.002       0.005\n",
      "educ           0.0604      0.008      7.642      0.000       0.045       0.076\n",
      "age            0.0577      0.008      7.548      0.000       0.043       0.073\n",
      "agesq         -0.0006   8.34e-05     -7.563      0.000      -0.001      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                      264.025   Durbin-Watson:                   1.908\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              960.743\n",
      "Skew:                          -1.531   Prob(JB):                    2.38e-209\n",
      "Kurtosis:                       7.381   Cond. No.                     1.88e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.88e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "results1.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   cigs   R-squared:                       0.051\n",
      "Model:                            OLS   Adj. R-squared:                  0.045\n",
      "Method:                 Least Squares   F-statistic:                     8.610\n",
      "Date:                Sat, 23 Apr 2022   Prob (F-statistic):           5.86e-08\n",
      "Time:                        18:13:13   Log-Likelihood:                -3237.0\n",
      "No. Observations:                 807   AIC:                             6486.\n",
      "Df Residuals:                     801   BIC:                             6514.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.5801     23.696      0.067      0.947     -44.933      48.093\n",
      "educ          -0.4501      0.162     -2.785      0.005      -0.767      -0.133\n",
      "age            0.8225      0.154      5.330      0.000       0.520       1.125\n",
      "agesq         -0.0096      0.002     -5.711      0.000      -0.013      -0.006\n",
      "lcigpric      -0.3513      5.766     -0.061      0.951     -11.669      10.966\n",
      "restaurn      -2.7364      1.110     -2.466      0.014      -4.915      -0.558\n",
      "==============================================================================\n",
      "Omnibus:                      226.788   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              500.148\n",
      "Skew:                           1.543   Prob(JB):                    2.48e-109\n",
      "Kurtosis:                       5.313   Cond. No.                     1.31e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.31e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "table_iv: \n",
      "                b      se        t    pval\n",
      "Intercept  7.7809  0.2299  33.8495  0.0000\n",
      "age        0.0938  0.0239   3.9331  0.0001\n",
      "agesq     -0.0011  0.0003  -3.8305  0.0001\n",
      "educ       0.0397  0.0163   2.4369  0.0150\n",
      "cigs      -0.0421  0.0262  -1.6067  0.1085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ch16 c1\n",
    "s = woo.dataWoo('SMOKE')\n",
    "\n",
    "# (i) b1 is the coefficient of the variable cigs and would\n",
    "# describe how being a cigarette smoker affects percentage\n",
    "# change in income.\n",
    "\n",
    "# (ii) i would expect that gamma5 has a negative sign, to follow the\n",
    "# law of demand. Gamma6 probably has a negative sign as well,\n",
    "# because local restrictions would reduce someone's ability\n",
    "# to smoke cigarettes.\n",
    "\n",
    "# (iii) te need at least one exogeneous variable that meets\n",
    "# the rank and order conditions in order for this equation\n",
    "# to be identified.\n",
    "\n",
    "reg = smf.ols(formula='lincome ~ cigs + educ + age + agesq', data=s)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# (iv) b1 is estimated to be 0.0017, but has a very large p-value, so\n",
    "# it is statistically insignificant and we can assume that being a\n",
    "# cigarette smoker does not affect income.\n",
    "\n",
    "reg1 = smf.ols(formula='cigs ~ educ + age + agesq + lcigpric + restaurn', data=s)\n",
    "results1 = reg1.fit()\n",
    "print(f'results1.summary(): \\n{results1.summary()}\\n')\n",
    "\n",
    "# (v) neither lcigpric nor restaurn are significant in the reduced form.\n",
    "\n",
    "reg_iv = iv.IV2SLS.from_formula(formula='lincome ~ 1 + [cigs ~ lcigpric + restaurn] + \\\n",
    "                                         age + educ + agesq', data=s)\n",
    "results_iv = reg_iv.fit(cov_type='unadjusted', debiased=True)\n",
    "table_iv = pd.DataFrame({'b': round(results_iv.params, 4),\n",
    "                         'se': round(results_iv.std_errors, 4),\n",
    "                         't': round(results_iv.tstats, 4),\n",
    "                         'pval': round(results_iv.pvalues, 4)})\n",
    "print(f'table_iv: \\n{table_iv}\\n')\n",
    "\n",
    "# (vi) the 2SLS model estimates B1 as negative, which is more expected\n",
    "# than the small positive sign in the OLS model. however, 2SLS\n",
    "# still includes cigs as a barely statistically insignificant variable.\n",
    "\n",
    "# (vii) i do not think that cigarette prices and restaurant smoking are\n",
    "# exogeneous in the income equation. income levels vary state-by-state,\n",
    "# and its likely that legal restaurant smoking is associated with states\n",
    "# that have lower income levels. also, cigarette prices are greatly\n",
    "# impacted by taxes, and taxes are probably higher in states with low\n",
    "# populations of smokers and high incomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04248b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch17 q2\n",
    "# the graduation probabily for someone who spends 10 hours per week in study hall is 99.9% \n",
    "# while someone who spend 5 hours has a 99.8% chance of graduating, making the estimated \n",
    "# different around 0.1%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b7bacf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asummary:\n",
      "                 id        educ           date      regprc      ecoprc  \\\n",
      "count    660.000000  660.000000     660.000000  660.000000  660.000000   \n",
      "mean   11729.009091   14.381818   68480.950000    0.882727    1.081515   \n",
      "std     1071.582702    2.274014   50777.930716    0.244469    0.295573   \n",
      "min    10002.000000    8.000000   10398.000000    0.590000    0.590000   \n",
      "25%    10800.500000   12.000000   11998.000000    0.590000    0.890000   \n",
      "50%    11692.000000   14.000000  111097.000000    0.890000    1.090000   \n",
      "75%    12600.250000   16.000000  112397.000000    1.190000    1.290000   \n",
      "max    13921.000000   20.000000  123197.000000    1.190000    1.590000   \n",
      "\n",
      "         inseason      hhsize        male      faminc         age      reglbs  \\\n",
      "count  660.000000  660.000000  660.000000  660.000000  660.000000  660.000000   \n",
      "mean     0.336364    2.940909    0.262121   53.409091   44.522727    1.282323   \n",
      "std      0.472823    1.526049    0.440122   35.741220   15.212539    2.909862   \n",
      "min      0.000000    1.000000    0.000000    5.000000   19.000000    0.000000   \n",
      "25%      0.000000    2.000000    0.000000   25.000000   33.000000    0.000000   \n",
      "50%      0.000000    3.000000    0.000000   45.000000   43.000000    0.000000   \n",
      "75%      1.000000    4.000000    1.000000   65.000000   53.000000    2.000000   \n",
      "max      1.000000    9.000000    1.000000  250.000000   88.000000   42.000000   \n",
      "\n",
      "           ecolbs      numlt5     num5_17    num18_64     numgt64  \n",
      "count  660.000000  660.000000  660.000000  660.000000  660.000000  \n",
      "mean     1.473990    0.286364    0.621212    1.804545    0.228788  \n",
      "std      2.525781    0.643489    0.994143    1.005136    0.548765  \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000    1.000000    0.000000  \n",
      "50%      1.000000    0.000000    0.000000    2.000000    0.000000  \n",
      "75%      2.000000    0.000000    1.000000    2.000000    0.000000  \n",
      "max     42.000000    4.000000    6.000000    7.000000    3.000000  \n",
      "\n",
      "results_tobit.summary(): \n",
      "                                Tobit Results                                 \n",
      "==============================================================================\n",
      "Dep. Variable:                 ecolbs   Log-Likelihood:                -1266.4\n",
      "Model:                          Tobit   AIC:                             2543.\n",
      "Method:            Maximum Likelihood   BIC:                             2565.\n",
      "Date:                Thu, 21 Apr 2022                                         \n",
      "Time:                        11:28:05                                         \n",
      "No. Observations:                 660                                         \n",
      "Df Residuals:                     655                                         \n",
      "Df Model:                           4                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.0027      0.668      1.501      0.133      -0.307       2.312\n",
      "ecoprc        -5.8215      0.886     -6.572      0.000      -7.558      -4.085\n",
      "regprc         5.6552      1.065      5.312      0.000       3.569       7.742\n",
      "faminc         0.0066      0.004      1.659      0.097      -0.001       0.014\n",
      "hhsize         0.1303      0.095      1.371      0.170      -0.056       0.317\n",
      "par0           1.2358      0.037     33.582      0.000       1.164       1.308\n",
      "==============================================================================\n",
      "\n",
      "fstat: 0.627913119393809\n",
      "\n",
      "fpval: 0.4284087309171545\n",
      "\n",
      "fstat: 0.10379233587698317\n",
      "\n",
      "fpval: 0.7474280864870934\n",
      "\n",
      "a.head(): \n",
      "       id  educ    date state  regprc  ecoprc  inseason  hhsize  male  faminc  \\\n",
      "0  10002    16  111597    SD    1.19    1.19         1       4     0      45   \n",
      "1  10004    16  121897    KS    0.59    0.79         0       1     0      65   \n",
      "2  10034    18  111097    MI    0.59    0.99         1       3     0      65   \n",
      "3  10035    12  111597    TN    0.89    1.09         1       2     1      55   \n",
      "4  10039    15  122997    NY    0.89    1.09         0       1     1      25   \n",
      "\n",
      "   age  reglbs    ecolbs  numlt5  num5_17  num18_64  numgt64  ecoprc_a  \\\n",
      "0   43     2.0  2.000000       0        1         3        0 -3.967936   \n",
      "1   37     0.0  2.000000       0        0         1        0 -3.114356   \n",
      "2   44     0.0  2.666667       0        2         1        0 -2.506764   \n",
      "3   55     3.0  0.000000       0        0         2        0 -3.123795   \n",
      "4   22     0.0  3.000000       0        0         1        0 -2.901726   \n",
      "\n",
      "   regprc_a  faminc_a  hhsize_a  \n",
      "0  3.854575  0.004525  0.088826  \n",
      "1  3.025382  0.003551  0.069718  \n",
      "2  2.435148  0.002858  0.056116  \n",
      "3  3.034551  0.003562  0.069929  \n",
      "4  2.818826  0.003309  0.064958  \n",
      "\n",
      "a.tail(): \n",
      "         id  educ   date state  regprc  ecoprc  inseason  hhsize  male  faminc  \\\n",
      "655  13892    14  20298    MD    0.59    0.59         0       5     0      65   \n",
      "656  13893    16  20398    OH    0.59    0.59         0       4     0      65   \n",
      "657  13908    16  20398    IN    0.89    1.09         0       2     0      75   \n",
      "658  13916    12  20298    NY    0.59    0.59         0       1     0      15   \n",
      "659  13921    18  20798    MA    1.19    1.39         0       3     1      25   \n",
      "\n",
      "     age    reglbs    ecolbs  numlt5  num5_17  num18_64  numgt64  ecoprc_a  \\\n",
      "655   37  1.333333  1.333333       1        2         2        0 -4.181261   \n",
      "656   47  0.000000  2.000000       0        2         2        0 -4.106017   \n",
      "657   51  1.000000  0.000000       0        0         2        0 -3.212846   \n",
      "658   45  0.000000  2.666667       0        0         1        0 -3.662777   \n",
      "659   24  2.000000  0.000000       0        0         3        0 -3.043892   \n",
      "\n",
      "     regprc_a  faminc_a  hhsize_a  \n",
      "655  4.061806  0.004768  0.093601  \n",
      "656  3.988712  0.004682  0.091917  \n",
      "657  3.121058  0.003664  0.071922  \n",
      "658  3.558135  0.004177  0.081994  \n",
      "659  2.956930  0.003471  0.068140  \n",
      "\n",
      "means:\n",
      "ecoprc_a   -3.192412\n",
      "regprc_a    3.101208\n",
      "faminc_a    0.003640\n",
      "hhsize_a    0.071465\n",
      "dtype: float64\n",
      "0.9999999999778808\n",
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 ecolbs   R-squared:                       0.039\n",
      "Model:                            OLS   Adj. R-squared:                  0.033\n",
      "Method:                 Least Squares   F-statistic:                     6.707\n",
      "Date:                Thu, 21 Apr 2022   Prob (F-statistic):           2.71e-05\n",
      "Time:                        11:28:05   Log-Likelihood:                -1534.3\n",
      "No. Observations:                 660   AIC:                             3079.\n",
      "Df Residuals:                     655   BIC:                             3101.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6295      0.450      3.618      0.000       0.745       2.514\n",
      "ecoprc        -2.9030      0.588     -4.935      0.000      -4.058      -1.748\n",
      "regprc         3.0306      0.711      4.263      0.000       1.635       4.426\n",
      "faminc         0.0028      0.003      1.037      0.300      -0.003       0.008\n",
      "hhsize         0.0537      0.064      0.841      0.401      -0.072       0.179\n",
      "==============================================================================\n",
      "Omnibus:                      993.848   Durbin-Watson:                   2.017\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           360854.165\n",
      "Skew:                           8.351   Prob(JB):                         0.00\n",
      "Kurtosis:                     116.327   Cond. No.                         588.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ch17 c9\n",
    "a = woo.dataWoo('APPLE')\n",
    "asummary = a.describe()\n",
    "print(f'asummary:\\n{asummary}\\n')\n",
    "\n",
    "# (i) 246 families report wanting none of the ecolabeled apples. \n",
    "\n",
    "# (ii) the variable ecolbs does seem to have continuous distribution over strictly \n",
    "# positive values, but also contains zero which means it would be suitable for a corner\n",
    "# solution tobit model. \n",
    "\n",
    "y, X = pt.dmatrices('ecolbs ~ ecoprc + regprc + faminc + hhsize', data=a)\n",
    "areg = smf.ols(formula='ecolbs ~ ecoprc + regprc + faminc + hhsize', data=a)\n",
    "results_a = areg.fit()\n",
    "sigma_start = np.log(sum(results_a.resid ** 2) / len(results_a.resid))\n",
    "params_start = np.concatenate((np.array(results_a.params), sigma_start), axis=None)\n",
    "class Tobit(smclass.GenericLikelihoodModel): \n",
    "    def nloglikeobs(self, params): \n",
    "        X = self.exog\n",
    "        y = self.endog\n",
    "        p = X.shape[1]\n",
    "        beta = params[0:p]\n",
    "        sigma = np.exp(params[p])\n",
    "        y_hat = np.dot(X, beta)\n",
    "        y_eq = (y == 0)\n",
    "        y_g = (y > 0)\n",
    "        l1 = np.empty(len(y))\n",
    "        l1[y_eq] = np.log(stats.norm.cdf((-y_hat)[y_eq] / sigma))\n",
    "        l1[y_g] = np.log(stats.norm.pdf((y - y_hat)[y_g] / sigma)) - np.log(sigma)\n",
    "        return -l1\n",
    "reg_tobit = Tobit(endog=y, exog=X)\n",
    "results_tobit = reg_tobit.fit(start_params=params_start, maxiter=10000, disp=0)\n",
    "print(f'results_tobit.summary(): \\n{results_tobit.summary()}\\n')\n",
    "\n",
    "# (iii) the variables ecoprc and regprc are significant at the 1% significance level. \n",
    "\n",
    "hypotheses = ['faminc = hhsize']\n",
    "ftest = results_a.f_test(hypotheses)\n",
    "fstat = ftest.statistic[0][0]\n",
    "fpval = ftest.pvalue\n",
    "print(f'fstat: {fstat}\\n')\n",
    "print(f'fpval: {fpval}\\n')\n",
    "\n",
    "# (iv) the f-test p value is 0.428, so therefore faminc and hhsize are not jointly \n",
    "# significant. \n",
    "\n",
    "# (v) the signs of the coefficients on the prices variables from part iii are as expected\n",
    "# since, assuming ecolabeled apples are a normal good, then price and quantity have an indirect \n",
    "# relationship. in response, the substitute good's, in this case regular apples would have a \n",
    "# direct relationship with the alternative's quantity because when the price of regular apples\n",
    "# goes up, more people will then buy ecolabed ones instead. \n",
    "\n",
    "hypotheses = ['ecoprc = -regprc']\n",
    "ftest = results_a.f_test(hypotheses)\n",
    "fstat = ftest.statistic[0][0]\n",
    "fpval = ftest.pvalue\n",
    "print(f'fstat: {fstat}\\n')\n",
    "print(f'fpval: {fpval}\\n')\n",
    "\n",
    "# (vi) the p-value is 0.747, so we fail to reject the null hypothesis that B1 = -B2. \n",
    "\n",
    "new_vars = ['ecoprc_a', 'regprc_a', 'faminc_a', 'hhsize_a']\n",
    "for i in range(len(new_vars)):\n",
    "    a[new_vars[i]] = beta[i+1] * stats.norm.cdf(X @ beta / sigma)\n",
    "print(f'a.head(): \\n {a.head()}\\n')\n",
    "print(f'a.tail(): \\n {a.tail()}\\n')\n",
    "print('means:')\n",
    "print(np.mean(a[new_vars], axis=0))\n",
    "\n",
    "# (vii) the smallest fitted value is 0.003640 and the largest is 3.101208. \n",
    "\n",
    "x_values = [-5.8215, 5.6552, 0.0066, 0.1303]\n",
    "y_values = [-3.192412, 3.101208, 0.003640, 0.071465]\n",
    "correlation_matrix = np.corrcoef(x_values, y_values)\n",
    "correlation_xy = correlation_matrix[0,1]\n",
    "r_squared = correlation_xy**2\n",
    "print(r_squared)\n",
    "\n",
    "# (viii) the squared correlation between ecolbs and ecolbshat is .99 repeated or 1. \n",
    "\n",
    "reg = smf.ols(formula='ecolbs ~ ecoprc + regprc + faminc + hhsize', data=a)\n",
    "results = reg.fit()\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# (ix) the ols estimates are significantly smaller than the tobit estimates because\n",
    "# the dataset contains a significant number of observations that equal zero, and the tobit\n",
    "# model censors these values. in terms of goodness of fit, the tobit model is superior as its\n",
    "# r-squared is 1 while the ols's is .039. \n",
    "\n",
    "# (x) had the r-squared from the tobit model been extremely small, the price still would\n",
    "# not have been considered inconsistent because the tobit model's aim is to maximize\n",
    "# log-liklihood, not the r-squared like in ols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d904e868",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 employ   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     6.441\n",
      "Date:                Sat, 23 Apr 2022   Prob (F-statistic):             0.0112\n",
      "Time:                        18:10:03   Log-Likelihood:                -2185.9\n",
      "No. Observations:                9822   AIC:                             4376.\n",
      "Df Residuals:                    9820   BIC:                             4390.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.9010      0.003    283.730      0.000       0.895       0.907\n",
      "abuse         -0.0283      0.011     -2.538      0.011      -0.050      -0.006\n",
      "==============================================================================\n",
      "Omnibus:                     4964.208   Durbin-Watson:                   1.963\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21268.339\n",
      "Skew:                          -2.631   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.929   Cond. No.                         3.38\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "\n",
      "results_pro.summary(): \n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 employ   No. Observations:                 9822\n",
      "Model:                         Probit   Df Residuals:                     9820\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 23 Apr 2022   Pseudo R-squ.:                0.001120\n",
      "Time:                        18:10:03   Log-Likelihood:                -3228.3\n",
      "converged:                       True   LL-Null:                       -3231.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                  0.007140\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.2872      0.018     70.630      0.000       1.252       1.323\n",
      "abuse         -0.1480      0.054     -2.723      0.006      -0.255      -0.041\n",
      "==============================================================================\n",
      "\n",
      "table_auto: \n",
      "  coef_names  APE_pro_autom\n",
      "0      abuse        -0.0263\n",
      "\n",
      "predictions_lin:\n",
      " 0    0.900995\n",
      "1    0.872690\n",
      "dtype: float64\n",
      "\n",
      "predictions_pro:\n",
      " 0    0.900995\n",
      "1    0.872690\n",
      "dtype: float64\n",
      "\n",
      "results.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 employ   R-squared:                       0.069\n",
      "Model:                            OLS   Adj. R-squared:                  0.068\n",
      "Method:                 Least Squares   F-statistic:                     29.23\n",
      "Date:                Sat, 23 Apr 2022   Prob (F-statistic):           3.49e-87\n",
      "Time:                        18:10:03   Log-Likelihood:                -1836.1\n",
      "No. Observations:                9822   AIC:                             3706.\n",
      "Df Residuals:                    9805   BIC:                             3828.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.1793      0.079      2.271      0.023       0.025       0.334\n",
      "abuse         -0.0202      0.011     -1.871      0.061      -0.041       0.001\n",
      "age            0.0160      0.003      5.123      0.000       0.010       0.022\n",
      "agesq         -0.0002   3.86e-05     -5.986      0.000      -0.000      -0.000\n",
      "educ           0.0369      0.008      4.778      0.000       0.022       0.052\n",
      "educsq        -0.0009      0.000     -3.087      0.002      -0.001      -0.000\n",
      "married        0.0574      0.010      5.623      0.000       0.037       0.077\n",
      "famsize        0.0030      0.002      1.267      0.205      -0.002       0.008\n",
      "white          0.0986      0.011      9.000      0.000       0.077       0.120\n",
      "northeast      0.0166      0.009      1.825      0.068      -0.001       0.034\n",
      "midwest        0.0047      0.009      0.536      0.592      -0.013       0.022\n",
      "south          0.0152      0.009      1.774      0.076      -0.002       0.032\n",
      "centcity      -0.0155      0.009     -1.759      0.079      -0.033       0.002\n",
      "outercity      0.0149      0.008      1.954      0.051   -4.73e-05       0.030\n",
      "qrt1          -0.0187      0.008     -2.238      0.025      -0.035      -0.002\n",
      "qrt2          -0.0067      0.008     -0.818      0.413      -0.023       0.009\n",
      "qrt3          -0.0016      0.008     -0.193      0.847      -0.018       0.015\n",
      "==============================================================================\n",
      "Omnibus:                     4507.768   Durbin-Watson:                   1.987\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17498.631\n",
      "Skew:                          -2.384   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.476   Cond. No.                     4.09e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large, 4.09e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "results1_pro.summary(): \n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 employ   No. Observations:                 9822\n",
      "Model:                         Probit   Df Residuals:                     9805\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Sat, 23 Apr 2022   Pseudo R-squ.:                 0.09346\n",
      "Time:                        18:10:03   Log-Likelihood:                -2929.9\n",
      "converged:                       True   LL-Null:                       -3231.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                3.110e-118\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -1.7628      0.376     -4.689      0.000      -2.500      -1.026\n",
      "abuse         -0.1208      0.057     -2.117      0.034      -0.233      -0.009\n",
      "age            0.0830      0.017      4.976      0.000       0.050       0.116\n",
      "agesq         -0.0012      0.000     -6.053      0.000      -0.002      -0.001\n",
      "educ           0.0827      0.027      3.017      0.003       0.029       0.137\n",
      "educsq      -8.77e-05      0.001     -0.077      0.939      -0.002       0.002\n",
      "married        0.3225      0.051      6.367      0.000       0.223       0.422\n",
      "famsize        0.0213      0.013      1.617      0.106      -0.005       0.047\n",
      "white          0.4595      0.046      9.984      0.000       0.369       0.550\n",
      "northeast      0.1300      0.057      2.288      0.022       0.019       0.241\n",
      "midwest        0.0575      0.052      1.095      0.273      -0.045       0.160\n",
      "south          0.1038      0.050      2.058      0.040       0.005       0.203\n",
      "centcity      -0.0700      0.049     -1.426      0.154      -0.166       0.026\n",
      "outercity      0.1105      0.048      2.283      0.022       0.016       0.205\n",
      "qrt1          -0.1079      0.051     -2.120      0.034      -0.208      -0.008\n",
      "qrt2          -0.0463      0.051     -0.901      0.368      -0.147       0.054\n",
      "qrt3          -0.0116      0.052     -0.221      0.825      -0.114       0.091\n",
      "==============================================================================\n",
      "\n",
      "table_auto: \n",
      "   coef_names  APE_pro_autom\n",
      "0       abuse        -0.0195\n",
      "1         age         0.0134\n",
      "2       agesq        -0.0002\n",
      "3        educ         0.0134\n",
      "4      educsq        -0.0000\n",
      "5     married         0.0520\n",
      "6     famsize         0.0034\n",
      "7       white         0.0741\n",
      "8   northeast         0.0210\n",
      "9     midwest         0.0093\n",
      "10      south         0.0167\n",
      "11   centcity        -0.0113\n",
      "12  outercity         0.0178\n",
      "13       qrt1        -0.0174\n",
      "14       qrt2        -0.0075\n",
      "15       qrt3        -0.0019\n",
      "\n",
      "table_iv: \n",
      "                b      se        t    pval\n",
      "Intercept  0.1732  0.0699   2.4786  0.0132\n",
      "age        0.0178  0.0031   5.7141  0.0000\n",
      "agesq     -0.0003  0.0000  -6.7429  0.0000\n",
      "centcity  -0.0072  0.0096  -0.7478  0.4546\n",
      "educ       0.0403  0.0059   6.8165  0.0000\n",
      "educsq    -0.0011  0.0002  -4.4724  0.0000\n",
      "famsize   -0.0013  0.0030  -0.4373  0.6619\n",
      "married    0.0536  0.0095   5.6425  0.0000\n",
      "midwest    0.0014  0.0093   0.1508  0.8801\n",
      "northeast  0.0170  0.0097   1.7519  0.0798\n",
      "outercity  0.0184  0.0084   2.2046  0.0275\n",
      "qrt1      -0.0181  0.0088  -2.0624  0.0392\n",
      "qrt2      -0.0057  0.0088  -0.6517  0.5146\n",
      "qrt3      -0.0042  0.0090  -0.4719  0.6370\n",
      "south      0.0125  0.0089   1.4048  0.1601\n",
      "white      0.1059  0.0097  10.8617  0.0000\n",
      "abuse     -0.3546  0.1544  -2.2971  0.0216\n",
      "\n",
      "table_secstg: \n",
      "                b      se        t    pval\n",
      "Intercept  0.9242  0.0143  64.5288  0.0000\n",
      "abuse     -0.2627  0.1411  -1.8618  0.0627\n",
      "resid      0.2357  0.1415   1.6656  0.0958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ch17 c15\n",
    "a = woo.dataWoo('ALCOHOL')\n",
    "a.describe()\n",
    "\n",
    "# (i) 89.8% of men in this sample were employed. 9.9% of men in this sample had \n",
    "# abused alcohol.\n",
    "\n",
    "reg = smf.ols(formula='employ ~ abuse', data=a)\n",
    "results = reg.fit(cov_type='HC3')\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# (ii) the regression equation implies that 90% of the men who do not abuse alcohol\n",
    "# are employed, and that being a man who abuses alcohol makes you 2.83% less\n",
    "# likely to be employed. the abuse coefficient is statistically significant,\n",
    "# and I did expect it to have a negative sign.\n",
    "\n",
    "reg_pro = smf.probit(formula='employ ~ abuse', data=a)\n",
    "results_pro = reg_pro.fit(disp=0)\n",
    "print(f'results_pro.summary(): \\n{results_pro.summary()}\\n')\n",
    "\n",
    "coef_names = np.array(results.model.exog_names)\n",
    "coef_names = np.delete(coef_names, 0)\n",
    "APE_pro_autom = results_pro.get_margeff().margeff\n",
    "table_auto = pd.DataFrame({'coef_names': coef_names,\n",
    "                          'APE_pro_autom':\n",
    "np.round(APE_pro_autom, 4)})\n",
    "print(f'table_auto: \\n{table_auto}\\n')\n",
    "\n",
    "# (iii) the sign and significance of the abuse coefficient are the same in the\n",
    "# probit model. the partial effects in the probit model are very similar\n",
    "# in the linear probability model.\n",
    "\n",
    "X_new = pd.DataFrame(\n",
    "    {'abuse': [0,1]})\n",
    "predictions_lin = results.predict(X_new)\n",
    "predictions_pro = results_pro.predict(X_new)\n",
    "print(f'predictions_lin:\\n {predictions_lin}\\n')\n",
    "print(f'predictions_pro:\\n {predictions_pro}\\n')\n",
    "\n",
    "# (iv) the predictions are the same for the LPM and the probit model.\n",
    "\n",
    "reg = smf.ols(formula='employ ~ abuse + age + agesq + educ + educsq + married \\\n",
    "                        + famsize + white + northeast + midwest + south + centcity + \\\n",
    "                        outercity + qrt1 + qrt2 + qrt3', data=a)\n",
    "results = reg.fit(cov_type='HC3')\n",
    "print(f'results.summary(): \\n{results.summary()}\\n')\n",
    "\n",
    "# (v) he coefficient is slightly smaller, but it is statistically\n",
    "# insignificant at the 5% level, so we assume that alcohol abuse\n",
    "# does not impact employment likelihood.\n",
    "\n",
    "reg1_pro = smf.probit(formula='employ ~ abuse  + age + agesq + educ + educsq + married + famsize + white + northeast + midwest + south + centcity + outercity + qrt1 + qrt2 + qrt3', data=alcohol)\n",
    "results1_pro = reg1_pro.fit(disp=0)\n",
    "print(f'results1_pro.summary(): \\n{results1_pro.summary()}\\n')\n",
    "\n",
    "coef_names = np.array(results1.model.exog_names)\n",
    "coef_names = np.delete(coef_names, 0)  # drop Intercept\n",
    "APE_pro_autom = results1_pro.get_margeff().margeff\n",
    "table_auto = pd.DataFrame({'coef_names': coef_names,\n",
    "                          'APE_pro_autom':\n",
    "np.round(APE_pro_autom, 4)})\n",
    "print(f'table_auto: \\n{table_auto}\\n')\n",
    "\n",
    "# (vi) the sign and significance of the abuse coefficient are the same in the\n",
    "# probit model. the partial effects in the probit model are very similar\n",
    "# in the linear probability model.\n",
    "# the APE for the abuse coefficient is -0.0195, which is smaller than\n",
    "# the LPM APE. however, the abuse coefficient in the probit model\n",
    "# is statistically significant. the estimations are no longer similar,\n",
    "# like they were in the simple regressions.\n",
    "\n",
    "# (vii) health status could be related to disability and age, both of which affect\n",
    "# employment ability. however, health status could also be correlated with\n",
    "# alcohol abuse. a version of the model including health could be investigated\n",
    "# to determine if health has any explanatory power.\n",
    "\n",
    "# (viii) abuse could be an endogenous variable because people experiencing unemployment\n",
    "# could use alcohol as a coping mechanism, leading to abuse. employment and\n",
    "# alcohol abuse could be determined bidirectionally. mother and father alcohol\n",
    "# abuse could be good instrumental variables because they could affect their\n",
    "# child's likelihood of abusing alcohol, but it could also be correlated with\n",
    "# the errors or with employment. testing is needed.\n",
    "\n",
    "reg_iv = iv.IV2SLS.from_formula(formula='employ ~ 1 + [abuse ~ fathalc + mothalc] + age + agesq + educ + educsq + married + famsize + white + northeast + midwest + south + centcity + outercity + qrt1 + qrt2 + qrt3', data=alcohol)\n",
    "results_iv = reg_iv.fit(cov_type='unadjusted', debiased=True)\n",
    "table_iv = pd.DataFrame({'b': round(results_iv.params, 4),\n",
    "                         'se': round(results_iv.std_errors, 4),\n",
    "                         't': round(results_iv.tstats, 4),\n",
    "                         'pval': round(results_iv.pvalues, 4)})\n",
    "print(f'table_iv: \\n{table_iv}\\n')\n",
    "\n",
    "#(ix) the instrumental variables coefficient is much larger than the LPM\n",
    "# coefficient.\n",
    "\n",
    "reg_redf = smf.ols(formula='abuse ~ fathalc + mothalc', data=a)\n",
    "results_redf = reg_redf.fit()\n",
    "a['resid'] = results_redf.resid\n",
    "reg_secstg = smf.ols(formula='employ ~ abuse + resid', data=a)\n",
    "results_secstg = reg_secstg.fit()\n",
    "\n",
    "table_secstg = pd.DataFrame({'b': round(results_secstg.params, 4),\n",
    "                             'se': round(results_secstg.bse, 4),\n",
    "                             't': round(results_secstg.tvalues, 4),\n",
    "                             'pval': round(results_secstg.pvalues, 4)})\n",
    "print(f'table_secstg: \\n{table_secstg}\\n')\n",
    "\n",
    "# (x) the residuals have a p-value under .10, so they are just barely\n",
    "# significant at the 10% and indicates that there could be\n",
    "# endogeneity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6522045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
